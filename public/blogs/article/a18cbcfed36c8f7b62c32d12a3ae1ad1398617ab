# RAG实战记录

- 检索（Retrieve）：拿用户 query 调搜索引擎 API，拿到搜素结果；
- 增强（Augmented）：设置提示词，把检索结果作为挂载上下文；
- 生成（Generation）：大模型回答问题，标注引用来源；


## 主要问题

- 响应速度
- 准确度

下述方案主要解决准确度，在准确的的前提下，尽可能的保证想要速度（例如切换更小的模型、优化更好的workflow）

## 方案

1. 意图识别 Intent Detection

主要实现方案有两种：
 - 第一种是内置问题库，把常见问题缓存起来，再跟用户提问做相似度匹配，如果用户提问命中关键词库，就直接大模型回复
 - 第二种是设置提示词，让大模型判断意图，【对搜索意图进行分类】

第一种方案会有枚举无法穷尽的问题，第二种方案主要问题在于大模型的识别准确度不够高。

2. 问题改写 query rewrite

主要包括三个维度的改写：
  - 让提问有更精准 / 更专业的表达
  - 补全上下文，做指代消解
  - 名词提取

3. 多信息源聚合 Multi Source

为了增加AI回复的可信度，对用户提问进行多信息检索，然后交给AI回复

4. 结果重排 Reranking

  - 过滤与query不符的结果
  - 上下文长度限制，利用重排截取最有价值的结果

5. 读取内容并构建上下文内容池
  
上下文内容池（Context Pool） = 历史搜索结果（Search Results）+ 历史对话消息（Chat Messages）

每次搜索后追问，都带上这个 Context Pool 做意图识别 / 问题改写，拿到新的检索结果后更新这个 Context Pool，并带上最新的 Context Pool 内容作为上下文请求大模型回答。

需要保证 Context Pool 的内容有较高的信息密度，同时要控制 Context Pool 的内容长度，不要超过大模型的 context 极限。

6. 提示词工程

需要大量精力用在提示词上，参考提示词工程博客


## 最后

**壁垒在于数据，而不是技术**

**我们需要不断的完善场景中的问题，来优化产品**

## 25-1-1 补充

- 知识库中的QA处理，可以使用处理成**对话**的逻辑，这个对话逻辑可以影响到大模型的回复逻辑
- QA中的A，内部也是可以加入的**变量**的。只要Q匹配到语义，A用其他标签来设置替代即可。
- QA可以使用**追问填槽**的逻辑
- 知识库中大量的应用**元数据**，回复用户时利用元数据完善答案
- 知识库一定要**打好标签**。
- 业务中 **全局状态和局部状态都需要记录**。