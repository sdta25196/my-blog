## ASCII

最基础的编码，是由美国人定义的，他们用1字节（8位）来定义他们使用的所有字符

由于英文就26个字母，256（2^8）个映射位足矣标识所有字符

实际上，ASCII只用了后面的7位（首位为0，形如 0xxx xxxx），定义了128个字符，以A为例：

`A -> 65 -> 0100 0001`

后来，各个国家都开始用编码来标识自己本国的语言，就出现了问题

1. 本国语言可能需要超过256个字符
2. 多国语言对于同一个映射位，有不同的解释，比如上面的65在美国是A，但是在其他国家就可能是别的含义了，大家交流很费事，需要频繁的转换

此时，unicode应运而生

## unicode 

unicode 源于一个很简单的想法：将全世界所有的字符包含在一个集合里，计算机只要支持这一个字符集，就能显示所有的字符，也就不会存在乱码了。

所以unicode也叫万国码、单一码，于2021年9月14日发布了14.0版本

从0开始，为每个符号指定一个编码，叫做**码点**，比如码点`61`就是`a`, 

```
  u+0061 = a
```

Unicode中的字符是分**区**定义的，每个区可以存放65536个（2^16）字符，称为一个平面（plane）。目前，一共有17个（25）平面，也就是说，整个Unicode字符集的大小现在是2^21。

最前面的65536个字符位，称为基本平面（缩写BMP），它的码点范围是从0一直到2^16-1，写成16进制就是从U+0000到U+FFFF。所有最常见的字符都放在这个平面，这是Unicode最先定义和公布的一个平面。其他16个平面被称为辅助平面(SMP)

unicode仅仅是规定一个字典（a == 61），但是并没有规定编码的具体实现方式，所以我们还会看到 `utf-8`、`utf16`等编码规则

### utf32

Unicode只规定了每个字符的码点，到底用什么样的字节序表示这个码点，就涉及到编码方法。

最直观的编码方法是，每个码点使用四个字节表示，字节内容一一对应码点。这种编码方法就叫做UTF-32。比如，码点0就用四个字节的0表示，码点597D就在前面加两个字节的0。

```
U+0000 = 0x0000 0000

U+597D = 0x0000 597D
```

> utf32使用4个人字节表示一个字符，完全对应unicode编码，这样查询效率虽然高O(1)，但是非常浪费空间，相比ASCII编码文件大了四倍

UTF-32的优点在于，转换规则简单直观，查找效率高。缺点在于浪费空间，同样内容的英语文本，它会比ASCII编码大四倍。这个缺点很致命，导致实际上没有人使用这种编码方法，HTML 5标准就明文规定，网页不得编码成UTF-32。

### utf8

人们真正需要的是一种节省空间的编码方法，这导致了UTF-8的诞生。**UTF-8是一种变长的编码方法，字符长度从1个字节到4个字节不等。**越是常用的字符，字节越短，最前面的128个字符，只使用1个字节表示，与ASCII码完全相同。

| 编号范围            | 字节 |
| ------------------- | ---- |
| 0x0000 - 0x007F     | 1    |
| 0x0080 - 0x07FF     | 2    |
| 0x0800 - 0xFFFF     | 3    |
| 0x010000 - 0x10FFFF | 4    |

由于UTF-8这种节省空间的特性，导致它成为互联网上最常见的网页编码。

### utf16

UTF-16编码介于UTF-32与UTF-8之间，同时结合了定长和变长两种编码方法的特点。

它的编码规则很简单：基本平面的字符占用2个字节，辅助平面的字符占用4个字节。**也就是说，UTF-16的编码长度要么是2个字节（U+0000到U+FFFF），要么是4个字节（U+010000到U+10FFFF）。**

| 编号范围            | 字节 |
| ------------------- | ---- |
| 0x0000 - 0xFFFF     | 2    |
| 0x010000 - 0x10FFFF | 4    |

于是就有一个问题，当我们遇到两个字节，怎么看出它本身是一个字符，还是需要跟其他两个字节放在一起解读？

在基本平面内，从U+D800到U+DFFF是一个空段，即这些码点不对应任何字符。因此，这个空段可以用来映射辅助平面的字符。

具体来说，辅助平面的字符位共有220个，也就是说，对应这些字符至少需要20个二进制位。UTF-16将这20位拆成两半，前10位映射在U+D800到U+DBFF（空间大小210），称为高位（H），后10位映射在U+DC00到U+DFFF（空间大小210），称为低位（L）。这意味着，一个辅助平面的字符，被拆成两个基本平面的字符表示。

> 从 (U+D800-U+DFFF)的范围内是一个空段，即这些码点不对应任何字符，在这个区间，划分了两个区间，其中4个字节里前2个字节是分配在 U+D800到U+DBFF 内，后2个字节是分配剩余的区间里(U+DC00 到 U+DFFF)，前者称高位(H)，后者称低位(L)，辅助平面就是利用了这个区间来映射字符。

**所以，当我们遇到两个字节，发现它的码点在U+D800到U+DBFF之间，就可以断定，紧跟在后面的两个字节的码点，应该在U+DC00到U+DFFF之间，这四个字节必须放在一起解读。**

```js
// 1. 首先获取该字符码点表示
let codePoint = '𝌆'.codePointAt() // 119558

// 2. 把码点的十进制转化16进制，可以发现已经超出了 U+FFFF(BMP) 范围，属于辅助平面
let codePointHEX = codePoint.toString(16) //1d306

// 3. 计算当前码点超出基本平面的部分
let dis =  (0x1d306 - 0x10000).toString(2) // 1101001100000110

// 4. 把超出的部分补0补够20位
0b0000110100 1100000110

// 5. 把这二十位的二进制进行高低位分割分别用16进制表示
// 添加 0xD800 从而映射到 高位(H)
0b0000110100.toString(16) + 0xD800 // 0x0034 + 0xD800 === 0xd834
//低位(L) 添加 0xDC00 从而映射到 低位(L)
0b1100000110.toString(16) + 0xDC00 // 0x0306 + 0xDC00 === 0xdf06

// 6.  最终的 utf-16编码为
0xd834 0xdf06
```

## JavaScript使用哪一种编码？

JavaScript语言采用Unicode字符集，但是只支持一种编码方法。

这种编码既不是UTF-16，也不是UTF-8，更不是UTF-32。上面那些编码方法，JavaScript都不用。

**JavaScript用的是UCS-2！**


### UCS-2编码


互联网还没出现的年代，曾经有两个团队，不约而同想搞统一字符集。一个是1988年成立的Unicode团队，另一个是1989年成立的UCS团队。等到他们发现了对方的存在，很快就达成一致：世界上不需要两套统一字符集。

1991年10月，两个团队决定合并字符集。也就是说，从今以后只发布一套字符集，就是Unicode，并且修订此前发布的字符集，UCS的码点将与Unicode完全一致。

UCS的开发进度快于Unicode，1990年就公布了第一套编码方法UCS-2，使用2个字节表示已经有码点的字符。（那个时候只有一个平面，就是基本平面，所以2个字节就够用了。）UTF-16编码迟至1996年7月才公布，明确宣布是UCS-2的超集，即基本平面字符沿用UCS-2编码，辅助平面字符定义了4个字节的表示方法。

两者的关系简单说，**就是UTF-16取代了UCS-2，或者说UCS-2整合进了UTF-16。**所以，现在只有UTF-16，没有UCS-2。

由于在JavaScript语言出现的时候，还没有UTF-16编码，所以只能选择UCS-2。

1995年5月，Brendan Eich用了10天设计了JavaScript语言；10月，第一个解释引擎问世；次年11月，Netscape正式向ECMA提交语言标准（整个过程详见《JavaScript诞生记》）。对比UTF-16的发布时间（1996年7月），就会明白Netscape公司那时没有其他选择，只有UCS-2一种编码方法可用！

### JavaScript字符函数的局限

**由于JavaScript只能处理UCS-2编码，造成所有字符在这门语言中都是2个字节，如果是4个字节的字符，会当作两个双字节的字符处理。**JavaScript的字符函数都受到这一点的影响，无法返回正确结果。

以字符`𝌆`为例，它的UTF-16编码是4个字节的`0xD834 DF06`。问题就来了，4个字节的编码不属于UCS-2，JavaScript不认识，只会把它看作单独的两个字符`U+D834`和`U+DF06`。前面说过，这两个码点是空的，所以JavaScript会认为是两个空字符组成的字符串！

```js
  '𝌆'.length // 2
  '𝌆' === '\u1d306' // false
  '𝌆'.charCodeAt(0) // 55348 (0xd834)

  '𝌆' === '\ud834\udf06' // true
```

解决这个问题，必须对码点做一个判断，然后手动调整。下面是正确的遍历字符串的写法。
```js
  while (++index < length) {
    // ...
    if (charCode >= 0xD800 && charCode <= 0xDBFF) {
      output.push(character + string.charAt(++index));
    } else {
      output.push(character);
    }
  }
```

## ES6

在es6中增强了unicode的支持，解决编码问题

* `fot of`可以正确拿到字符

```js
for (let s of '𝌆𝌆' ) {
  // 此处可以拿到s是正确的字符 𝌆
}
```

* `Array.from`可以正确获得字符串长度

```js
Array.from('𝌆').length  // 1
```

* 码点表示法

JavaScript允许直接用码点表示Unicode字符，写法是"反斜杠+u+码点"。`'好' === '\u597D' // true`

但是，这种表示法对4字节的码点无效。ES6修正了这个问题，只要将码点放在大括号内，就能正确识别

```js
  '𝌆' === '\u1d306' // false
  '𝌆' === '\u{1d306}' // true
```

* 新增字符串处理函数

```js
String.fromCodePoint() // 从Unicode码点返回对应字符
String.prototype.codePointAt() // 从字符返回对应的码点
String.prototype.at() // 返回字符串给定位置的字符
```